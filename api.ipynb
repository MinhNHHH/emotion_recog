{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CUzPVOuhPHfV"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iMSwfMFPVOO",
    "outputId": "5d08073c-f9da-4fb9-9f9b-7ce38d05f466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utils\n",
      "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ow0of99PPKnm"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "from fastai.vision import *\r\n",
    "from fastai.metrics import accuracy\r\n",
    "from fastai.basic_data import *\r\n",
    "from skimage.util import montage\r\n",
    "from fastai.callbacks.hooks import num_features_model\r\n",
    "from torch.nn import L1Loss\r\n",
    "import pandas as pd\r\n",
    "from torch import optim\r\n",
    "import re\r\n",
    "import json\r\n",
    "import cv2\r\n",
    "import types\r\n",
    "import fastai\r\n",
    "#from fastprogress import force_console_behavior\r\n",
    "import fastprogress\r\n",
    "fastprogress.fastprogress.NO_BAR = True\r\n",
    "#master_bar, progress_bar = force_console_behavior()\r\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar\r\n",
    "from PIL import Image\r\n",
    "from utils import *\r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBFGBkd8PLQ5",
    "outputId": "d64145e8-c73b-4552-a08b-f14d2fbc8bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KhgOzoKePLTN"
   },
   "outputs": [],
   "source": [
    "path1 = Path('/content/drive/MyDrive/FaceDetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xzn-D3rLPLVr"
   },
   "outputs": [],
   "source": [
    "path2 = Path('/content/drive/MyDrive/emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IIRHeR7iczC9"
   },
   "outputs": [],
   "source": [
    "class StubbedObjectCategoryList(ObjectCategoryList):\r\n",
    "    def analyze_pred(self, pred): return [pred.unsqueeze(0), torch.ones(1).long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rz4kMftXcu4b"
   },
   "outputs": [],
   "source": [
    "class FaceDetector(nn.Module):\r\n",
    "    def __init__(self, arch=models.resnet18):\r\n",
    "        super().__init__() \r\n",
    "        self.cnn = create_body(arch)\r\n",
    "        self.head = create_head(num_features_model(self.cnn) * 2, 4)\r\n",
    "        \r\n",
    "    def forward(self, im):\r\n",
    "        x = self.cnn(im)\r\n",
    "        x = self.head(x)\r\n",
    "        return 2 * (x.sigmoid_() - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VUtvLD7Jc2FK"
   },
   "outputs": [],
   "source": [
    "def loss_fn(preds, targs, class_idxs):\r\n",
    "    return L1Loss()(preds, targs.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yc0XLNyac2H7"
   },
   "outputs": [],
   "source": [
    "def intersection(preds, targs):\r\n",
    "    # preds and targs are of shape (bs, 4), pascal_voc format\r\n",
    "    max_xy = torch.min(preds[:, 2:], targs[:, 2:])\r\n",
    "    min_xy = torch.max(preds[:, :2], targs[:, :2])\r\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\r\n",
    "    return inter[:, 0] * inter[:, 1]\r\n",
    "\r\n",
    "def area(boxes): \r\n",
    "    return ((boxes[:, 2]-boxes[:, 0]) * (boxes[:, 3]-boxes[:, 1]))\r\n",
    "\r\n",
    "def union(preds, targs):\r\n",
    "    return area(preds) + area(targs) - intersection(preds, targs)\r\n",
    "\r\n",
    "def IoU(preds, targs):\r\n",
    "    return intersection(preds, targs) / union(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4z-G5zxvc2K9"
   },
   "outputs": [],
   "source": [
    "def acc_detection(preds, targs, _):\r\n",
    "  return IoU(preds, targs.squeeze()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ULq5IbqSc2N5"
   },
   "outputs": [],
   "source": [
    "metrics = acc_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kOYEtRthPLYN"
   },
   "outputs": [],
   "source": [
    "learn1 = load_learner(path1,file='facedetec.pkl')\r\n",
    "learn2 = load_learner(path2,file='emotion.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "QY9WqxTYPLbI"
   },
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox, target=None, color=(255, 0, 0), thickness=2):\r\n",
    "     y_min, x_min, y_max, x_max = map(int, bbox)\r\n",
    "     cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\r\n",
    "     #if target is not None:\r\n",
    "      #   y_min, x_min, y_max, x_max = map(int, target)\r\n",
    "      #   cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=(0,255,0), thickness=thickness)\r\n",
    "     return img\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "_02B3YWHPLdw"
   },
   "outputs": [],
   "source": [
    "def cv_read(path):    \r\n",
    "     im = cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
    "     im1 = cv2.resize(im,(224,224))\r\n",
    "     return cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "6C112IcTOMgI"
   },
   "outputs": [],
   "source": [
    "def img_fastai(img):\r\n",
    "  return vision.Image(pil2tensor(img,np.float32).div_(255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "vaK7pwzXeJvF"
   },
   "outputs": [],
   "source": [
    "a = PIL.Image.open(f\"/content/thieu1.jpg\").resize((224,224), resample=PIL.Image.BICUBIC).save(f\"/content/thieu1.jpg\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "4fVb5txoOLbf"
   },
   "outputs": [],
   "source": [
    "def find_bbox(img,learn):\r\n",
    "  input = img_fastai(img)\r\n",
    "  lb,pred_idx,preds = learn.predict(input)\r\n",
    "  SZ=224\r\n",
    "  predicted_bboxes = ((preds + 1) / 2 * SZ).numpy()\r\n",
    "  ims = np.stack([draw_bbox(img, predicted_bboxes)])\r\n",
    "  return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "DHM2UrtzQ6AU"
   },
   "outputs": [],
   "source": [
    "def emotion_detect(img,learn):\r\n",
    "  lbel= ['happy','neutral','sad']\r\n",
    "  input = img_fastai(montage(np.stack(img), multichannel=True))\r\n",
    "  lb,pred_idx,preds = learn.predict(input)\r\n",
    "  return lbel[np.argmax(lb,axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "pTC97wKsJome"
   },
   "outputs": [],
   "source": [
    "img1 = cv_read('/content/pem1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aiwu-qxZGe_",
    "outputId": "595e9b46-eaf9-47c4-b24d-2737d2475421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "ohfNnOIUQEWw"
   },
   "outputs": [],
   "source": [
    "bbox = find_bbox(img1,learn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "73LkmtHXSaGY"
   },
   "outputs": [],
   "source": [
    "emotion = emotion_detect(bbox,learn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBqv4oSpXuoF"
   },
   "outputs": [],
   "source": [
    "plt.title(emotion)\r\n",
    "plt.imshow(montage(np.stack(bbox), multichannel=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4We0UzVPLlh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXqlU0TPPLnz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I59IYUDPLqZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZlcipvlPLsw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYF4X3eQPLvt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxtBOA9JPLyu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi6TCSsiPL18"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0Gw3LWcPL4R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBGUQTsvPL7j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tw3y0sXePL98"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "app.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
